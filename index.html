<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <br>
    <div class="logo" style="text-align: center; width: 5%;">
        <a href="index.html">
            <img src="./assets/images/optimus3.png">
        </a>
    </div>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="Optimus-3: Towards Generalist Multimodal Minecraft Agents with Scalable Task Experts">
    <title>Optimus-3: Towards Generalist Multimodal Minecraft Agents with Scalable Task Experts</title>
    <script>

    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="./static/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<body>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Optimus-3: Towards Generalist Multimodal Minecraft Agents with Scalable Task Experts</h1>
                        
                        <span class="author-block">
                            <a target="_blank"
                                href="https://scholar.google.com/citations?user=TDBF2UoAAAAJ&hl=en&oi=ao">Zaijing&#160;Li</a><sup>1
                                2</sup>,
                            <a target="_blank"
                                href="https://scholar.google.com/citations?user=KO77A2oAAAAJ&hl=en">Yuquan&#160;Xie</a><sup>1
                            </sup>,
                            <a target="_blank"
                                href="https://scholar.google.com/citations?user=9Vc--XsAAAAJ&hl=en&oi=ao">Rui&#160;Shao</a><sup>1&#9993</sup>,
                            <a target="_blank"
                                href="https://scholar.google.com/citations?user=Mpg0w3cAAAAJ&hl=en&oi=ao">Gongwei&#160;Chen</a><sup>1</sup>,
                            <br>
                            <a target="_blank"
                                href="https://ieeexplore.ieee.org/author/37087008154">Weili&#160;Guan</a><sup>1</sup>,
                            <a target="_blank"
                                href="https://scholar.google.com/citations?hl=en&user=Awsue7sAAAAJ">Dongmei&#160;Jiang</a><sup>2</sup>,
                            <a target="_blank"
                                href="https://scholar.google.com/citations?hl=en&user=yywVMhUAAAAJ">Liqiang&#160;Nie</a><sup>1&#9993</sup>,
                            <div class="is-size-5 publication-authors" style="font-size: 10px;">
                                <span class="author-block"><sup>1</sup>Harbin Institute of Technology,
                                    Shenzhen&#160&#160&#160</span>
                                <span class="author-block"><sup>2</sup>Peng Cheng Laboratory, Shenzhen</span>
                            </div>


                            <div class="is-size-5 publication-authors" style="font-size: 10px;">
                                <span class="author-block"><sup>&#9993&#160;</sup>Corresponding
                                    author&#160;&#160;</span>
                            </div>
                            <div class="column has-text-centered">
                                <div class="publication-links">
                                    <span class="link-block">
                                        <a target="_blank" href="https://arxiv.org/abs/2502.19902"
                                            class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="ai ai-arxiv"></i>
                                            </span>
                                            <span>arXiv</span>
                                        </a>
                                    </span>

                                    <span class="link-block">
                                        <a target="_blank" href="https://arxiv.org/pdf/2502.19902"
                                            class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="fas fa-file-pdf"></i>
                                            </span>
                                            <span>PDF</span>
                                        </a>
                                    </span>
                                    <!-- Code Link. -->
                                    <span class="link-block">
                                        <a target="_blank" href="https://github.com/JiuTian-VL/Optimus-3"
                                            class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="fab fa-github"></i>
                                            </span>
                                            <span>Code</span>
                                        </a>
                                    </span>
                                    <br />

                                </div>

                            </div>
                    </div>

                </div>
            </div>
        </div>
    </section>


    <section class="section" style="background-color:#ffffff">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3">Optimus-3</h2>
                        <img src="assets/images/fig1.png" class="interpolation-image" alt=""
                            style="display: block; margin-left: auto; margin-right: auto" width="800" height="700" />
                        <br>
                        <span style="font-size: 110%">
                            Demonstration of Optimus-3â€™s capabilities as a generalist agent in Minecraft. It can 
                            perform long-horizon task planning, captioning, embodied QA, grounding, low-level 
                            action generation, and reflection in an interactive manner. All of these capabilities 
                            are seamlessly integrated into a unified end-to-end architecture, enabling robust and 
                            coherent performance across diverse task scenarios.</span>
                    </div>
                </div>
            </div>
        </div>
    </section>
    
    <section class="section" style="background-color:#efeff081">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p style="font-size: 125%">
                            Recently, agents based on multimodal large language models (MLLMs) have achieved remarkable progress across various domains. 
                            However, building a generalist agent with capabilities such as perception, planning, action, grounding, and reflection in open-world 
                            environments like Minecraft remains challenges: insufficient domain-specific data, interference among heterogeneous tasks, 
                            and visual diversity in open-world settings. In this paper, we address these challenges through three key contributions. 
                            <b>(1)</b> We propose a knowledge-enhanced data generation pipeline to provide scalable and high-quality training data for agent development.
                            <b>(2)</b> To mitigate interference among heterogeneous tasks, we introduce a Mixture-of-Experts (MoE) architecture with task-level routing.
                            <b>(3)</b> We develop a Multimodal Reasoning-Augmented Reinforcement Learning approach to enhance the agent's reasoning ability for visual 
                            diversity in Minecraft. Built upon these innovations, we present Optimus-3, a general-purpose agent for Minecraft. 
                            Extensive experimental results demonstrate that Optimus-3 surpasses both generalist multimodal large language models 
                            and existing state-of-the-art agents across a wide range of tasks in the Minecraft environment.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    
    <section class="section" style="background-color:#ffffff">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3">Data Generation Pipeline</h2>
                        <img src="assets/images/fig3.png" class="interpolation-image" alt=""
                            style="display: block; margin-left: auto; margin-right: auto" width="800" height="700" />
                        <br>
                        <span style="font-size: 110%">
                            Given a task pool, we utilize a knowledge graph to generate task plans, forming the planning dataset. 
                            These plans are then used as instructions for STEVE-1, which interacts with the environment to produce 
                            the action dataset. During this process, we randomly sample images and employ expert models with  environmental 
                            feedback to generate the captioning, embodied QA, and grounding datasets.</span>
                    </div>
                </div>
            </div>
        </div>
    </section>
   

    <section class="section" style="background-color:#efeff081">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3">Overview framework</h2>
                        <img src="assets/images/fig2.png" class="interpolation-image" alt=""
                            style="display: block; margin-left: auto; margin-right: auto" width="800" height="700" />
                        <br>
                        <span style="font-size: 110%">
                            <b>A</b>: The architecture of Optimus-3, which includes a task router that selects a specific task expert for each query,
                            a ViT for visual encoding, and a MoE LLM for generating responses and low-level actions. Given a long-horizon task, 
                            it can generate a feasible plan and then execute the sub-goals sequentially. 
                            <b>B</b>: The proposed Multimodal Reasoning-Augmented Reinforcement Learning effectively enhances the agent's performance. 
                            <b>C</b>: Performance comparison of Optimus-3 against current task-specific SOTA agents, GPT-4o, and the original backbone Qwen2.5-VL.</span>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <!-- result -->
    <section class="section" style="background-color:#ffffff">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">Experiment</span></h2>
                        <span style="font-size: 110%"> Main Result of Optimus-3 on Long-Horizon tasks, Planning, Captioning, Embodied QA, Grounding, and Reflection. 
                        </span>
                        <h1><span class="dvima">Table1: Main Result of Optimus-3 on Long-Horizon tasks. </span></h1>
                        <img src="assets/images/table1.png" class="interpolation-image" alt="" width="500" height="250"
                            style="display: block; margin-left: auto; margin-right: auto" />
                        <br>


                        <h1><span class="dvima"><span class="dvima">Table2: Main Result of Optimus-3 on Planning, Captioning, Embodied QA, Grounding, and Reflection.</span></h1>
                        <div class="image-container">
                            <div class="image-wrapper">
                                <img src="assets/images/table2.png" alt="" width="600" height="800"
                                    style="margin-left: auto; margin-right: auto" />
                            </div>
                        </div>
                        <br>
                    </div>
                </div>

            </div>
        </div>
    </section>

    <!--Conclusion-->
    <section class="section" style="background-color:#efeff081">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <h2 class="title is-3"><span class="dvima">Conclusion</span></h2>

                        <p style="font-size: 125%">
                            We introduce Optimus-3, which endowed with comprehensive capabilities in perception, planning, action, and reflection 
                            within the Minecraft. We propose a knowledge-enhanced data generation pipeline to support agent training, 
                            a task-level routing MoE to address interference among heterogeneous tasks, and a multimodal reasoning-augmented reinforcement 
                            learning method to improve performance on vision-related tasks. Extensive experimental results demonstrate that Optimus-3 
                            marks a significant step forward toward building a generalist agent in Minecraft.
                        </p>

                    </div>
                </div>

            </div>
        </div>
    </section>


</body>

</html>
